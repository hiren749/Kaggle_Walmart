{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings, itertools \n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Total Data \n",
    "\n",
    "For this notebook, I simplify the analysis and aggregate all departments together to produce sales by store. I furthermore only model one store and perform extensive visualization and diagnostics as I proceed. I will next generalize to more stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "train.columns = train.columns.str.lower()\n",
    "train.set_index('date', inplace=True)\n",
    "\n",
    "weekly_sales = train.groupby([train.index, 'store']).sum()[['weekly_sales']]\n",
    "weekly_sales = weekly_sales.reset_index(level=1)\n",
    "\n",
    "train, test = train_test_split(weekly_sales, test_size = 0.2, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "\n",
    "Our simple baseline model will be predicting a store's sales for the following week will equal the previous week. Given the statinary of weekly sales for most stores, this shouldn't be a terrible prediction for most stores. This will not account for any trends in sales or seasonality effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sid in range(45):\n",
    "    base_RMSE = np.sqrt((weekly_sales['weekly_sales'].diff().dropna()**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2010-02-05           NaN\n",
       "2010-02-05     23.083809\n",
       "2010-02-05    362.930372\n",
       "2010-02-05     78.379807\n",
       "2010-02-05    573.179368\n",
       "                 ...    \n",
       "2012-10-26     30.023949\n",
       "2012-10-26    155.760474\n",
       "2012-10-26     12.397384\n",
       "2012-10-26     62.740831\n",
       "2012-10-26     52.508761\n",
       "Name: weekly_sales, Length: 6435, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(abs(weekly_sales['weekly_sales'].diff())/weekly_sales['weekly_sales']*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_RMSE = np.sqrt((weekly_sales['weekly_sales'].diff().dropna()**2).mean())\n",
    "base_pct_RMSE = \n",
    "print('RMSE of simple basline model: ${:.2f}'.format(base_RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
